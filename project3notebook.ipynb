{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\"> <h1 style=\"color:green; margin-bottom:20px\">Reviewers comment v1</h1>\n",
    "\n",
    "Hello Tyler!\n",
    "\n",
    "I'm happy to review your project today ðŸ™Œ\n",
    "\n",
    "My name isÂ **Justino Imbert** ([this](https://hub.tripleten.com/u/125e88ae) is my Hub profile) and today I'll be reviewing your project!\n",
    "\n",
    "\n",
    "You can find my comments under the heading **Â«ReviewÂ»**. I will categorize my comments in green, yellow, red or blue boxes like this:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Success:</b> if everything is done successfully\n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b>Remarks:</b> if I can give some recommendations or ways to improve the project\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    <b>Needs fixing:</b> if the block requires some corrections. Work cant be accepted with the red comments\n",
    "</div>\n",
    "\n",
    "Please dont remove my comments :) If you have any questions dont hesitate to respond to my comments in a different section. \n",
    "<div class=\"alert alert-info\"> <b>Student comments:</b> For example like this</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "\n",
    "    \n",
    "<b>Overall Feedback</b>\n",
    "    \n",
    "Hello Tyler,\n",
    "    \n",
    "Youâ€™ve submitted another projectâ€”great work! Your commitment to pushing through the challenges of this program is admirable.\n",
    "\n",
    "After reviewing your submission, it is approved.\n",
    "    \n",
    "   \n",
    "You can find my more detailed notes within your project notebook in the `Reviewer's comment v1:` section.\n",
    "\n",
    "If you find yourself uncertain or in need of further insights, never hesitate to consult with your tutor or ask your questions here. We are here to guide and assist you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which one is a better plan?\n",
    "\n",
    "You work as an analyst for the telecom operator Megaline. The company offers its clients two prepaid plans, Surf and Ultimate. The commercial department wants to know which of the plans brings in more revenue in order to adjust the advertising budget.\n",
    "\n",
    "You are going to carry out a preliminary analysis of the plans based on a relatively small client selection. You'll have the data on 500 Megaline clients: who the clients are, where they're from, which plan they use, and the number of calls they made and text messages they sent in 2018. Your job is to analyze the clients' behavior and determine which prepaid plan brings in more revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Great job keeping the additional information about the project goal! Additionally, you could add a short description of the tasks you plan to perform and the available data. This information could be helpful for the notebook reader.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I've consolidated the tabs, please make sure each is opened to see the informartion needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Below, I am going to write code to analyze data from Megaline to determine, between the Surf plan and the Ultimate plan, which provides more revenue. My initial hypothesis before looking at the data is that the Surf plan will bring in less money than the Utimate. The base charge for Ultimate is $50 higher than the Surf and the large difference in minutes, texts, and data  and the super small amounts included for the Surf plan might just lead a majority to buy the Ultimate over the Surf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the libraries\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data files into different DataFrames\n",
    "megaline_calls_df = pd.read_csv('/datasets/megaline_calls.csv')\n",
    "megaline_internet_df = pd.read_csv('/datasets/megaline_internet.csv')\n",
    "megaline_messages_df = pd.read_csv('/datasets/megaline_messages.csv')\n",
    "megaline_plans_df = pd.read_csv('/datasets/megaline_plans.csv')\n",
    "megaline_users_df = pd.read_csv('/datasets/megaline_users.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the data below, im searching through the dataframes to correct any data neccessary for my analysis to work.\n",
    "#right off the bat, im seeing that every date is type object, I will probably want to change that so i can call on specific\n",
    "#months or days in my calculations. I also want to follow Megalines charging rules when veiwing and correcting usage columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#its important to note that the data is from every session, call, and text occuring,\n",
    "#so depending on the route we take, I might need to combine these data points for each unique user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   messages_included      2 non-null      int64  \n",
      " 1   mb_per_month_included  2 non-null      int64  \n",
      " 2   minutes_included       2 non-null      int64  \n",
      " 3   usd_monthly_pay        2 non-null      int64  \n",
      " 4   usd_per_gb             2 non-null      int64  \n",
      " 5   usd_per_message        2 non-null      float64\n",
      " 6   usd_per_minute         2 non-null      float64\n",
      " 7   plan_name              2 non-null      object \n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 256.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the general/summary information about the plans' DataFrame\n",
    "print(megaline_plans_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of data for plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   messages_included  mb_per_month_included  minutes_included  \\\n",
      "0                 50                  15360               500   \n",
      "1               1000                  30720              3000   \n",
      "\n",
      "   usd_monthly_pay  usd_per_gb  usd_per_message  usd_per_minute plan_name  \n",
      "0               20          10             0.03            0.03      surf  \n",
      "1               70           7             0.01            0.01  ultimate  \n"
     ]
    }
   ],
   "source": [
    "print(megaline_plans_df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not seeing any issues with this df. data describes the plans limits and overage costs,which we will use late when calculating revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the general/summary information about the users' DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megaline_users_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of data for users\n",
    "print(megaline_users_df.sample(5))\n",
    "#I do see that churn_date has many less non-null counts than the rest of the data, will have to look into what that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this df shows the users information, as well as join and churn dates(NaN in churn shows they are still active)\n",
    "#in a different project, we could use this information in many ways, like calculating minutes, messages, and data usage based on age group\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fix obvious issues with the data given the initial observations.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so after further analysis, churn date represents the date users stopped using the service.\n",
    "#This means that the NaN values represent active users and this is very important data.\n",
    "#in the future, i may need to create a seperate df for user that have churn dates.\n",
    "#Maybe theres specific months that users tend to cancel their services, so lets keep that in mind moving forward.\n",
    "\n",
    "megaline_users_df['reg_date'] = pd.to_datetime(megaline_users_df['reg_date'])\n",
    "#reg_date to datetime like the others\n",
    "print(megaline_users_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the general/summary information about the calls' DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megaline_calls_df.info())\n",
    "#Megaline likes to round every individual call up, so ill have to correct the duration. I will change the type to int as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of data for calls\n",
    "print(megaline_calls_df.sample(5))\n",
    "#Megaline likes to round every individual call up, so ill have to correct the duration. I will change the type to int as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megaline_calls_df['duration'] = np.ceil(megaline_calls_df['duration'])\n",
    "megaline_calls_df['duration'] = megaline_calls_df['duration'].astype(int)\n",
    "megaline_calls_df['call_date'] = pd.to_datetime(megaline_calls_df['call_date'])\n",
    "\n",
    "#i'm using the .ceil method to raise my values to the next integer value. \n",
    "#and changing the type to int should help with calculations in the future.\n",
    "#also changed call date to type datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megaline_calls_df.info())\n",
    "print(megaline_calls_df.head())\n",
    "\n",
    "#looks like that fixed my issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the general/summary information about the messages' DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megaline_messages_df.info())\n",
    "#not seeing any non null differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of data for messages\n",
    "print(megaline_messages_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id like to convert my dates into datetime for the purpose of breaking down monthly information\n",
    "#ill probably only use user id and dates here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megaline_messages_df['message_date'] = pd.to_datetime(megaline_messages_df['message_date'])\n",
    "#converting date to type datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megaline_messages_df.info())\n",
    "print(megaline_messages_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Add additional factors to the data if you believe they might be useful.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the general/summary information about the internet DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megaline_internet_df.info())\n",
    "#not seeing any non null differences\n",
    "#HOWEVER, we will need to round the values for the months usage to align with Megalines charging style.\n",
    "#we will round it to the next whole GB and convert to int ONCE WE NEED THE VALUES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of data for the internet traffic\n",
    "print(megaline_internet_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will need to convert these dates to datetime as well. when we get to using the mb information, we will round up\n",
    "#for now im keeping it just incase i need the info. I will probably make a seperate df for rounding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fix obvious issues with the data given the initial observations.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megaline_internet_df['session_date'] = pd.to_datetime(megaline_internet_df['session_date'])\n",
    "#just converting date to datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megaline_internet_df.info())\n",
    "print(megaline_internet_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Add additional factors to the data if you believe they might be useful.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Great data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study plan conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[It is critical to understand how the plans work, how users are charged based on their plan subscription. So, we suggest printing out the plan information to view their conditions once again.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the plan conditions and make sure they are clear for you\n",
    "#Note: Megaline rounds seconds up to minutes, and megabytes to gigabytes. For calls, each individual call is rounded up:\n",
    "#even if the call lasted just one second, it will be counted as one minute. For web traffic, \n",
    "#individual web sessions are not rounded up. Instead, the total for the month is rounded up. \n",
    "#If someone uses 1025 megabytes this month, they will be charged for 2 gigabytes.\n",
    "\n",
    "print(megaline_plans_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of calls made by each user per month. Save the result.\n",
    "megaline_calls_df['month'] = megaline_calls_df['call_date'].dt.month\n",
    "calls_per_month = megaline_calls_df.groupby(['user_id', 'month']).count()\n",
    "#this works, but theres too many useless columns\n",
    "calls_per_month = calls_per_month.drop(columns= ['call_date', 'duration']).rename(columns= {'id': 'calls'}).reset_index()\n",
    "#dropped useless columns and renamed one to describe the data.had to reset_index because the multi-indexing made the data look weird \n",
    "print(calls_per_month.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the amount of minutes spent by each user per month. Save the result.\n",
    "minutes_per_month = megaline_calls_df.groupby(['user_id', 'month']).agg('sum')\n",
    "#using agg allows us to add the duration columns for the specific months and users and removes other datatype columns automatically\n",
    "#this only works because the duration column is the only other column that can be aggragated. otherwise id need to remove the other data\n",
    "minutes_per_month = minutes_per_month.reset_index()\n",
    "print(minutes_per_month.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of messages sent by each user per month. Save the result.\n",
    "megaline_messages_df['month'] = megaline_messages_df['message_date'].dt.month\n",
    "messages_per_month = megaline_messages_df.groupby(['user_id', 'month']).count()\n",
    "messages_per_month = messages_per_month.drop(columns = ['message_date']).rename(columns = {'id': 'messages'}).reset_index()\n",
    "#like before dropped useless columns, renamed column for accurate data , and reset index\n",
    "print(messages_per_month.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the volume of internet traffic used by each user per month. Save the result.\n",
    "#by GB rounded up, we will have to add the MB the round with .ceil then convert to in and sum with agg\n",
    "megaline_internet_df['month'] = megaline_internet_df['session_date'].dt.month\n",
    "mb_per_month = megaline_internet_df.groupby(['user_id', 'month']).agg('sum').reset_index()\n",
    "#assuming we round up the mb before conversion\n",
    "mb_per_month['mb_used'] = np.ceil(mb_per_month['mb_used'])\n",
    "mb_per_month['mb_used'] = mb_per_month['mb_used'].astype(int)\n",
    "#1024 megabytes per gigabytes\n",
    "gb_per_month = mb_per_month.copy()\n",
    "#make a copy of the previous dataframe instead of replacing, might not be neccessary but if we need to call back itll be easier\n",
    "gb_per_month['gb_used'] = mb_per_month['mb_used'] / 1024\n",
    "gb_per_month = gb_per_month.drop(columns = ['mb_used'])\n",
    "#dont need this in the gb df\n",
    "gb_per_month['gb_used'] = np.ceil(gb_per_month['gb_used'])\n",
    "gb_per_month['gb_used'] = gb_per_month['gb_used'].astype('int')\n",
    "\n",
    "print(gb_per_month.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Put the aggregate data together into one DataFrame so that one record in it would represent what an unique user consumed in a given month.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Very good job grouping the data for each dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data for calls, minutes, messages, internet based on user_id and month\n",
    "user_monthly_usage = messages_per_month.merge(minutes_per_month, on = ['user_id', 'month'], how = 'outer')\n",
    "user_monthly_usage = user_monthly_usage.merge(gb_per_month, on = ['user_id', 'month'], how = 'outer')\n",
    "print(user_monthly_usage.info())\n",
    "print(user_monthly_usage.sample(5))\n",
    "#table looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok so we have null data, thats not a bad thing, since it just means they didnt use whatever the null value is under\n",
    "#so ill just replace any null value with 0\n",
    "user_monthly_usage = user_monthly_usage.fillna(0)\n",
    "user_monthly_usage.info()\n",
    "user_monthly_usage.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Good job making sure there are no missing values and using the correct value to replace those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the plan information\n",
    "user_monthly_all = user_monthly_usage.merge(megaline_users_df[['user_id', 'plan']], on = 'user_id', how = 'left')\n",
    "user_monthly_all = user_monthly_all.merge(megaline_plans_df, left_on= 'plan', right_on = 'plan_name', how = 'left')\n",
    "user_monthly_all = user_monthly_all.drop(columns= ['plan_name'])\n",
    "print(user_monthly_all.head())\n",
    "#....tell me why it says they round up to gb every month but they put the limit down as mb_per_month_included. geez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Well done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Calculate the monthly revenue from each user (subtract the free package limit from the total number of calls, text messages, and data; multiply the result by the calling plan value; add the monthly charge depending on the calling plan). N.B. This might not be as trivial as just a couple of lines given the plan conditions! So, it's okay to spend some time on it.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the monthly revenue for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_monthly_stats = user_monthly_all.copy()\n",
    "#creating a copy of the df above to add a new df with additional stats\n",
    "user_monthly_stats['minutes_overage'] = np.maximum(0, user_monthly_all['duration'] - user_monthly_all['minutes_included'])\n",
    "user_monthly_stats['messages_overage'] = np.maximum(0,user_monthly_all['messages'] - user_monthly_all['messages_included'])\n",
    "user_monthly_stats['data_overage'] = np.maximum(0, user_monthly_all['gb_used'] - user_monthly_all['mb_per_month_included']/1024)\n",
    "user_monthly_stats['minutes_overage_cost'] = user_monthly_stats['minutes_overage'] * user_monthly_all['usd_per_minute']\n",
    "user_monthly_stats['messages_overage_cost'] = user_monthly_stats['messages_overage'] * user_monthly_all['usd_per_message']\n",
    "user_monthly_stats['data_overage_cost'] = user_monthly_stats['data_overage'] * user_monthly_all['usd_per_gb']\n",
    "user_monthly_stats['total_cost'] = user_monthly_stats['data_overage_cost'] + user_monthly_stats['messages_overage_cost'] + user_monthly_stats['minutes_overage_cost'] + user_monthly_all['usd_monthly_pay']\n",
    "print(user_monthly_stats.sample(5))\n",
    "print(user_monthly_stats.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what ive done here is use the np library method .maximum to test if the values in each of the minute,message, and data columns\n",
    "#exceeded the maximums set by the plans and add the new data to new columns.\n",
    "#I then found the cost of these overages by multiplying the results of the prev. code by the cost of overage and made new columns\n",
    "#for those. I will now make a datafram with just the costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Well done! Now, to take your project to the next level, think about creating a function that performs the calculation, so you could call it anywhere in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_monthly_cost = user_monthly_stats[['user_id', 'plan', 'month', 'minutes_overage_cost', 'messages_overage_cost', 'data_overage_cost', 'usd_monthly_pay', 'total_cost']]\n",
    "print(user_monthly_cost.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study user behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Calculate some useful descriptive statistics for the aggregated and merged data, which typically reveal an overall picture captured by the data. Draw useful plots to help the understanding. Given that the main task is to compare the plans and decide on which one is more profitable, the statistics and the plots should be calculated on a per-plan basis.]\n",
    "\n",
    "[There are relevant hints in the comments for Calls but they are not provided for Messages and Internet though the principle of statistical study is the same for them as for Calls.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the method and routes taken for each section will be identical because we are looking for the same information in each.\n",
    "#i would suggest tabbing the data when your finished looking voer it so you dont get confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_monthly_stats = user_monthly_stats[user_monthly_stats['plan'] == 'surf']\n",
    "ultimate_monthly_stats = user_monthly_stats[user_monthly_stats['plan'] == 'ultimate']\n",
    "#ill be using these for information we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_monthly_duration = surf_monthly_stats.groupby('month')['duration'].mean().reset_index()\n",
    "ultimate_monthly_duration = ultimate_monthly_stats.groupby('month')['duration'].mean().reset_index()\n",
    "#monthly_avg_duration = user_monthly_stats.groupby('month')['duration'].mean()-doesnt group\n",
    "monthly_avg_duration = surf_monthly_duration.merge(ultimate_monthly_duration, on = 'month', how= 'left', suffixes = ['_surf', '_ultimate'])\n",
    "print(monthly_avg_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare average duration of calls per each plan per each distinct month. Plot a bar plat to visualize it.\n",
    "monthly_avg_duration.plot(kind= 'bar', x= 'month', xlabel= \"Month\", ylabel= \"Average Duration of Calls\", title= \"Comparison of Average Call Duration Between Surf Plan and Ultimate Plan\", rot= 0)\n",
    "plt.legend(['Surf Plan', 'Ultimate Plan'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thers no clear conclusion here.\n",
    "#only visible conclusion I can see is there is a slight positive correlation. \n",
    "#meaning everyones call durations slightly increase on average from Jan to Dec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the number of minutes users of each plan require each month. Plot a histogram.\n",
    "surf_user_monthly_duration = surf_monthly_stats.groupby(['user_id', 'month'])['duration'].sum().reset_index()\n",
    "ultimate_user_monthly_duration = ultimate_monthly_stats.groupby(['user_id', 'month'])['duration'].sum().reset_index()\n",
    "monthly_user_duration = surf_user_monthly_duration.merge(ultimate_user_monthly_duration, on = 'month', how= 'left', suffixes = ['_surf', '_ultimate'])\n",
    "print(monthly_user_duration.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i opted to use the seperate dataframes for the plans because i found it easier to process mentally.\n",
    "surf_user_monthly_duration['duration'].plot(kind = 'hist', alpha= .5, bins= 12)\n",
    "ultimate_user_monthly_duration['duration'].plot(kind = 'hist', alpha= .5, bins= 12)\n",
    "plt.xlabel('Monthly Call Duration in Minutes')\n",
    "plt.ylabel('Amount of User-Month')\n",
    "plt.title('Comparison of Monthly Call Duration for Surf and Ultimate Plans')\n",
    "plt.legend(['Surf Duration', 'Ultimate Duration'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more users in the surf plan, distribution looks similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Calculate the mean and the variable of the call duration to reason on whether users on the different plans have different behaviours for their calls.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and the variance of the monthly call duration\n",
    "print(\"Surf Plan:\")\n",
    "print(\"Mean-\", surf_user_monthly_duration['duration'].mean())\n",
    "print(\"Variance-\", surf_user_monthly_duration['duration'].var())\n",
    "print(\"Standard Deviation-\", surf_user_monthly_duration['duration'].std())\n",
    "#no need to make it difficult since ive already got the data seperated.\n",
    "print()\n",
    "print()\n",
    "print(\"Ultimate Plan:\")\n",
    "print(\"Mean-\", ultimate_user_monthly_duration['duration'].mean())\n",
    "print(\"Variance-\", ultimate_user_monthly_duration['duration'].var())\n",
    "print(\"Standard Deviation-\", ultimate_user_monthly_duration['duration'].std())\n",
    "#looks like the Mean and Variance are higher for the Ultimate Plan, meaning users using the Ultimate plan\n",
    "#tend to use slightly more minutes per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to normal distribution, not entirely accurate to our data, but provides insight\n",
    "distr_surf_duration= st.norm(428.50, 234.453)\n",
    "below_500_duration = distr_surf_duration.cdf(500)\n",
    "print(\"% Surf Users Below 500 Minutes Used:\", below_500_duration)\n",
    "above_500_duration = distr_surf_duration.cdf(5000) - distr_surf_duration.cdf(500)\n",
    "print(\"% Surf Users Above 500 Minutes Used:\", above_500_duration)\n",
    "#We know no Ultimate user exceeded their limit, so we wont bother looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this doesnt show how many minutes over,but it gives us a good look into what we can expect when we calculate revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1, axis2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "surf_user_monthly_duration['duration'].plot(kind='box', ax=axis1, title='Surf Plan Minutes Used', ylabel= \"Duration in Min\")\n",
    "ultimate_user_monthly_duration['duration'].plot(kind='box', ax=axis2, title='Ultimate Plan Minutes Used', ylabel= \"Duration in Min\")\n",
    "axis1.set_xticklabels([])\n",
    "axis2.set_xticklabels([])\n",
    "axis1.set_xticks([])\n",
    "axis2.set_xticks([])\n",
    "#i thought it would look cleaner to have the descriptor on the side with the numbers, rather than the bottom. what a headache though\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The values being so similar to the the Surf plan means that there are many people paying\n",
    "#for the Ultimate plan who dont use anywhere near as many minutes as they have available.\n",
    "#On the opposite hand, it seems like a decent percentage of Surf users actually go over their minute limit.\n",
    "\n",
    "#Looking at the data, i would conclude that most people, behave the same in terms of mintues used.\n",
    "#there is a slight uptick in call duration for Ultimate, but i think analyzing a bigger dataset would make them look almost identical.\n",
    "#we will probably see a good amount of additional charges for those in the Surf plan, but it doesnt push us to an overall conclusion by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Formulate conclusions on how the users behave in terms of calling. Is their behaviour different between the plans?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the number of messages users of each plan tend to send each month\n",
    "surf_monthly_messages = surf_monthly_stats.groupby('month')['messages'].mean().reset_index()\n",
    "ultimate_monthly_messages = ultimate_monthly_stats.groupby('month')['messages'].mean().reset_index()\n",
    "\n",
    "monthly_avg_messages = surf_monthly_messages.merge(ultimate_monthly_messages, on = 'month', how= 'left', suffixes = ['_surf', '_ultimate'])\n",
    "print(monthly_avg_messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_avg_messages.plot(kind= 'bar', x= 'month', xlabel= \"Month\", ylabel= \"Average Text Messages\", title= \"Comparison of Average Text Messages Between Surf Plan and Ultimate Plan\", rot= 0)\n",
    "plt.legend(['Surf Plan', 'Ultimate Plan'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theres clearly more text messages being sent by people with the Ultimate plan on average\n",
    "#also seeing a similar positive correlation as the calls graph had from Jan-Dec.\n",
    "#wonder if thats going to be the same for the rest of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_user_monthly_messages = surf_monthly_stats.groupby(['user_id', 'month'])['messages'].sum().reset_index()\n",
    "ultimate_user_monthly_messages = ultimate_monthly_stats.groupby(['user_id', 'month'])['messages'].sum().reset_index()\n",
    "#this is only here if you want it all in one dataframe\n",
    "monthly_user_messages = surf_user_monthly_messages.merge(ultimate_user_monthly_messages, on = 'month', how= 'left', suffixes = ['_surf', '_ultimate'])\n",
    "print(surf_user_monthly_messages.sample(5))\n",
    "print(ultimate_user_monthly_messages.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_user_monthly_messages['messages'].plot(kind = 'hist', alpha= .5, bins= 12)\n",
    "ultimate_user_monthly_messages['messages'].plot(kind = 'hist', alpha= .5, bins= 12)\n",
    "\n",
    "plt.xlabel('Monthly Text Messages')\n",
    "plt.ylabel('Amount of User-Month')\n",
    "plt.title('Comparison of Monthly Text Messages for Surf and Ultimate Plans')\n",
    "plt.legend(['Surf Messages', 'Ultimate Messages'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more users in the surf plan\n",
    "#pretty big spikes at or near 0 here, i guess a bunch of users on both plans dont text much or at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Surf Plan:\")\n",
    "print(\"Mean-\", surf_user_monthly_messages['messages'].mean())\n",
    "print(\"Variance-\", surf_user_monthly_messages['messages'].var())\n",
    "print(\"Standard Deviation-\", surf_user_monthly_messages['messages'].std())\n",
    "print()\n",
    "print()\n",
    "print(\"Ultimate Plan:\")\n",
    "print(\"Mean-\", ultimate_user_monthly_messages['messages'].mean())\n",
    "print(\"Variance-\", ultimate_user_monthly_messages['messages'].var())\n",
    "print(\"Standard Deviation-\", ultimate_user_monthly_messages['messages'].std())\n",
    "\n",
    "\n",
    "#once again, it looks like the Mean and Variance are higher for the Ultimate Plan, meaning users using the Ultimate Plan\n",
    "#tend to send more text messages per month.\n",
    "#these numbers being as low as they are has me thinking people will be using data way more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to normal distribution, not entirely accurate to our data, but provides insight\n",
    "distr_surf_messages= st.norm(31.160, 33.567)\n",
    "below_50_messages = distr_surf_messages.cdf(50)\n",
    "print(\"% Surf Users Below 50 Messages Sent:\", below_50_messages)\n",
    "above_50_messages = distr_surf_messages.cdf(1000) - distr_surf_messages.cdf(50)\n",
    "print(\"% Surf Users Above 50 Messages Sent:\", above_50_messages)\n",
    "#We know no Ultimate user exceeded their limit, so we wont bother looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this doesnt show how many Messages over,but it gives us a good look into what we can expect when we calculate revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1, axis2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "surf_user_monthly_messages['messages'].plot(kind='box', ax=axis1, title='Surf Plan Texts Sent', ylabel= \"Number of Text Messages\")\n",
    "ultimate_user_monthly_messages['messages'].plot(kind='box', ax=axis2, title='Ultimate Plan Texts Sent', ylabel= \"Number of Text Messages\")\n",
    "axis1.set_xticklabels([])\n",
    "axis2.set_xticklabels([])\n",
    "axis1.set_xticks([])\n",
    "axis2.set_xticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WOAH, within an std, most users in the surf plan tended to stay within their 50 texts limit\n",
    "#while ultimate users texted more, noone ever even got near the limit.\n",
    "#there is still a sizeable handful of users exceeding the limit on the Surf plan, so im expecting a lot of charges there.\n",
    "#if the data on data usage looks anything like our last two sets of information, i can see the Surf plan being the most profitable for Megaline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Formulate conclusions on how the users behave in terms of messaging. Is their behaviour different between the plans?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the amount of internet traffic consumed by users per plan\n",
    "surf_monthly_data = surf_monthly_stats.groupby('month')['gb_used'].mean().reset_index()\n",
    "ultimate_monthly_data = ultimate_monthly_stats.groupby('month')['gb_used'].mean().reset_index()\n",
    "\n",
    "monthly_avg_data = surf_monthly_data.merge(ultimate_monthly_data, on = 'month', how= 'left', suffixes = ['_surf', '_ultimate'])\n",
    "print(monthly_avg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_avg_data.plot(kind= 'bar', x= 'month', xlabel= \"Month\", ylabel= \"Average Data Usage(GB)\", title= \"Comparison of Average Data Usage Between Surf Plan and Ultimate Plan\", rot= 0)\n",
    "plt.legend(['Surf Plan', 'Ultimate Plan'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genuinly surprised at the results here.\n",
    "#the Ultimate plan has a slightly larger avg usage\n",
    "#however, i expected more traffic from both plans\n",
    "#there is again an uptick throughout the year leading to a slight positive correlation for mostly the Surf(less so for the Ultimate Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_user_monthly_data = surf_monthly_stats.groupby(['user_id', 'month'])['gb_used'].sum().reset_index()\n",
    "ultimate_user_monthly_data = ultimate_monthly_stats.groupby(['user_id', 'month'])['gb_used'].sum().reset_index()\n",
    "#this is only here if you want it all in one dataframe\n",
    "monthly_user_data = surf_user_monthly_data.merge(ultimate_user_monthly_data, on = 'month', how= 'left', suffixes = ['_surf', '_ultimate'])\n",
    "print(surf_user_monthly_data.sample(5))\n",
    "print(ultimate_user_monthly_data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_user_monthly_data['gb_used'].plot(kind = 'hist', alpha= .5, bins= 12)\n",
    "ultimate_user_monthly_data['gb_used'].plot(kind = 'hist', alpha= .5, bins= 12)\n",
    "\n",
    "plt.xlabel('Monthly Data Usage')\n",
    "plt.ylabel('Amount of User-Month')\n",
    "plt.title('Comparison of Monthly Data Usage for Surf and Ultimate Plans')\n",
    "plt.legend(['Surf GB Used', 'Ultimate GB Used'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once again significantly more Surf Plan users than Ultimate\n",
    "#both have similar trends. a key observation here is that while the avgs for the Surf plan were around the usage limit\n",
    "#there is a sizeable amount that exceed that.\n",
    "#a smaller amount but still noticable exceed the ultimate limit as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Surf Plan:\")\n",
    "print(\"Mean-\", surf_user_monthly_data['gb_used'].mean())\n",
    "print(\"Variance-\", surf_user_monthly_data['gb_used'].var())\n",
    "print(\"Standard Deviation-\", surf_user_monthly_data['gb_used'].std())\n",
    "print()\n",
    "print()\n",
    "print(\"Ultimate Plan:\")\n",
    "print(\"Mean-\", ultimate_user_monthly_data['gb_used'].mean())\n",
    "print(\"Variance-\", ultimate_user_monthly_data['gb_used'].var())\n",
    "print(\"Standard Deviation-\", ultimate_user_monthly_data['gb_used'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to normal distribution, not entirely accurate to our data, but provides insight\n",
    "distr_surf_data= st.norm(16.671,7.848)\n",
    "surf_below_15_gb = distr_surf_data.cdf(15)\n",
    "print(\"Surf Users Below 15 GB Usage:\", surf_below_15_gb)\n",
    "surf_above_15_gb = distr_surf_data.cdf(1000) - distr_surf_data.cdf(15)\n",
    "#noones using 1000gb \n",
    "print(\"Surf Users Above 15 GB Usage:\", surf_above_15_gb)\n",
    "#This time we do have ultimate users that have exceeded their limits so we will check that\n",
    "\n",
    "distr_ultimate_data = st.norm(17.3069, 7.670)\n",
    "ultimate_below_30_gb = distr_ultimate_data.cdf(30)\n",
    "print(\"Ultimate Users Below 30 GB Usage:\", ultimate_below_30_gb)\n",
    "ultimate_above_30_gb = distr_ultimate_data.cdf(1000) - distr_ultimate_data.cdf(30)\n",
    "print(\"Ultimate Users Above 30 GB Usage:\", ultimate_above_30_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this doesnt show how many GB over,but it gives us a good look into what we can expect when we calculate revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1, axis2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "surf_user_monthly_data['gb_used'].plot(kind='box', ax=axis1, title='Surf Plan GB Used', ylabel= \"Number of GB Used\")\n",
    "ultimate_user_monthly_data['gb_used'].plot(kind='box', ax=axis2, title='Ultimate Plan GB Used', ylabel= \"Number of GB Used\")\n",
    "axis1.set_xticklabels([])\n",
    "axis2.set_xticklabels([])\n",
    "axis1.set_xticks([])\n",
    "axis2.set_xticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirms what i wrote before, many surf users exceed the data limits while only some exceed the ultimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Formulate conclusions on how the users tend to consume the internet traffic? Is their behaviour different between the plans?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Likewise you have studied the user behaviour, statistically describe the revenue between the plans.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this one, we will be using the user_monthly_cost dataframe we created earlier, we should just be able to take the sumn of\n",
    "#the revenues for each plan and have our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_user_monthly_cost = user_monthly_cost[user_monthly_cost['plan'] == 'surf']\n",
    "ultimate_user_monthly_cost = user_monthly_cost[user_monthly_cost['plan'] == 'ultimate']\n",
    "print(surf_user_monthly_cost.sample(5))\n",
    "print()\n",
    "print()\n",
    "print(ultimate_user_monthly_cost.sample(5))\n",
    "\n",
    "#just loading the data to make sure we have the right information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we are looking for the totals here, im not going to need to keep the user Ids anymore, just the months.\n",
    "\n",
    "surf_overall_monthly_cost = surf_user_monthly_cost.groupby('month')['minutes_overage_cost', 'messages_overage_cost', 'data_overage_cost', 'usd_monthly_pay', 'total_cost'].sum()\n",
    "print(surf_overall_monthly_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_overall_monthly_cost = ultimate_user_monthly_cost.groupby('month')['minutes_overage_cost', 'messages_overage_cost', 'data_overage_cost', 'usd_monthly_pay', 'total_cost'].sum()\n",
    "print(ultimate_overall_monthly_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the sake of just looking at total cost, im going to take the original data and only have total cost colums and months\n",
    "#then split those\n",
    "#I will then sum for the year as well to get yearly revenue.\n",
    "\n",
    "#would thing I will point out is that for some reason, neight have any users to start with, it then ramps up throught the year.\n",
    "#this could be why we saw a positive correlation, because most of the users joined later in the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_total_monthly_revenue = surf_user_monthly_cost.groupby('month')['total_cost'].sum()\n",
    "ultimate_total_monthly_revenue = ultimate_user_monthly_cost.groupby('month')['total_cost'].sum()\n",
    "print(surf_total_monthly_revenue)\n",
    "print(ultimate_total_monthly_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_revenue = pd.DataFrame({\n",
    "    'surf_revenue': surf_total_monthly_revenue,\n",
    "    'ultimate_revenue': ultimate_total_monthly_revenue})\n",
    "\n",
    "print(monthly_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Yearly Surf Revenue:\", monthly_revenue['surf_revenue'].sum())\n",
    "print(\"Yearly Ultimate Revenue:\", monthly_revenue['ultimate_revenue'].sum())\n",
    "\n",
    "year_surf_revenue = monthly_revenue['surf_revenue'].sum()\n",
    "year_ultimate_revenue = monthly_revenue['ultimate_revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the revenues increase throughout the year, indicating that more of the 500 users joined later in the year\n",
    "#also the total year revenue from the surf plan is much higher than that of the ultimate plan, which proves my personal\n",
    "#hypothesis wrong.Before further testing, It initially indicates that we could reasonably give the advertisement team feedback with \n",
    "#a good degree of certainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Formulate conclusions about how the revenue differs between the plans.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "The analysis you have carried out for each section is impeccable; you show very valuable analysis, and I consider the conclusions in each section to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test statistical hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Test the hypothesis that the average revenue from users of the Ultimate and Surf calling plans differs.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Formulate the null and the alternative hypotheses, choose the statistical test, decide on the alpha value.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I will find the avg total monthly revenues for both plans, combine the into a single df and then test my hypothesis\n",
    "surf_avg_total_monthly_revenue = surf_user_monthly_cost.groupby('month')['total_cost'].mean().reset_index()\n",
    "ultimate_avg_total_monthly_revenue = ultimate_user_monthly_cost.groupby('month')['total_cost'].mean().reset_index()\n",
    "print(surf_avg_total_monthly_revenue)\n",
    "print(ultimate_avg_total_monthly_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_monthly_revenue = surf_avg_total_monthly_revenue.merge(ultimate_avg_total_monthly_revenue, on = 'month', how = 'left')\n",
    "avg_monthly_revenue = avg_monthly_revenue.rename(columns= {'total_cost_x': 'surf_avg_revenue', 'total_cost_y': 'ultimate_avg_revenue'})\n",
    "print(avg_monthly_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypotheses\n",
    "alpha = .005\n",
    "#i want my answer to be as accurate as possible, we cannot leave it up to chance\n",
    "results = st.ttest_ind(avg_monthly_revenue['surf_avg_revenue'], avg_monthly_revenue['ultimate_avg_revenue'], equal_var= False)\n",
    "#testing the hypothesis that the average revenue between plans differs, since we want to provide feedback about advertisement\n",
    "#and want to know if they should focus on one or the other\n",
    "print('p-value:', results.pvalue) \n",
    "\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "\n",
    "    print(\"We reject the hypothesis that the plans bring in the same revenue\")\n",
    "else:\n",
    "    print(\"We can't reject the hypothesis that the plans bring in the same revenue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perfect! we've shown up to within .5% degree of error that the plan revenues are not the same! they should look into advertising\n",
    "#the surf plan more than ultimate plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Test the hypothesis that the average revenue from users in the NY-NJ area is different from that of the users from the other regions.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Formulate the null and the alternative hypotheses, choose the statistical test, decide on the alpha value.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first i have to create a whole new dataframe with the cities.\n",
    "megaline_users_city = megaline_users_df[['user_id', 'city']] \n",
    "print(megaline_users_city.sample(5))\n",
    "user_monthly_cost_with_city = user_monthly_cost.merge(megaline_users_city, on= 'user_id', how= 'left')\n",
    "print(user_monthly_cost_with_city.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now ill seperate those with NY|NJ in the name and then we will grab the averages for both the ny|nj and otherwise.\n",
    "user_monthly_cost_nynj = user_monthly_cost_with_city[user_monthly_cost_with_city['city'].str.contains('ny|nj', case= False, na = False)]\n",
    "print(user_monthly_cost_nynj.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_monthly_cost_without_nynj = user_monthly_cost_with_city[~user_monthly_cost_with_city['city'].str.contains('ny|nj', case= False, na = False)]\n",
    "print(user_monthly_cost_without_nynj.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nynj_average_revenue = user_monthly_cost_nynj.groupby('month')['total_cost'].mean().reset_index()\n",
    "other_cities_average_revenue = user_monthly_cost_without_nynj.groupby('month')['total_cost'].mean().reset_index()\n",
    "#getting the averages for the monthly revenue for NYNJ and the other cities in seperate df\n",
    "print(nynj_average_revenue)\n",
    "print(other_cities_average_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "#since we are testing area average revenue for specific cities, i think we can iclude a bit more wiggle room \n",
    "results = st.ttest_ind(nynj_average_revenue['total_cost'], other_cities_average_revenue['total_cost'], equal_var= False)\n",
    "#testing the hypothesis that the average revenue between citties revenue is the same\n",
    "print('p-value:', results.pvalue) \n",
    "\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "\n",
    "    print(\"We reject the hypothesis that NY-NJ has the same revenue than other cities\")\n",
    "else:\n",
    "    print(\"We can't reject the hypothesis that NY-NJ has the same revenue as the other cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within a 5% degree of error, we cant reject the hypothesis that NY-NJ has the same revenue as the other cities\n",
    "#this would lead me to suggest that they dont focus on aNY-NJ cities over other cities when advertising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Very good work!, the only thing I would add is to explicitly include the null and alternative hypotheses for each test so we know what we want to test before running the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General conclusion\n",
    "\n",
    "[List your important conclusions in this final section, make sure they cover all those important decisions (assumptions) that you've made and that led you to the way you processed and analyzed the data.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of conclusion\n",
    "#-there are more surf plan users than ultimate plan users\n",
    "#-The surf plan brought in more revenue that the ultimate plan in this dataset\n",
    "#-within a .05% degree of error, we confirmed that we can reject our null hypotheses that our plans produce the same revenue\n",
    "#-within a 5% degree of error, we confirmed that we can't reject the hypothesis that NYNJ has the same revenue as other cities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    "\n",
    "That is correct but, one of the most important things for a project are the final conclusions because they bring together the entire analysis into clear and actionable insights. While the technical process shows how the data was explored, modeled, and tested, the conclusions explain what it all means and why it matters. Strong conclusions:\n",
    "\n",
    "- **Synthesize findings:** They summarize the most important results without overwhelming the reader with technical details.\n",
    "\n",
    "- **Provide interpretation:** They translate numbers, models, and metrics into meaningful insights that answer the original research question or business problem.\n",
    "\n",
    "- **Show impact:** They highlight the practical implications of the work, such as recommendations, limitations, or next steps.\n",
    "\n",
    "- **Demonstrate critical thinking:** They prove that the student not only applied methods correctly but also understood their significance in context.\n",
    "\n",
    "Without well-written conclusions, even the most sophisticated analysis can feel incomplete, because the reader is left unsure about the value and implications of the work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 828,
    "start_time": "2021-11-16T09:21:11.304Z"
   },
   {
    "duration": 893,
    "start_time": "2021-11-16T09:21:17.728Z"
   },
   {
    "duration": 1150,
    "start_time": "2021-11-16T09:21:29.568Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:24:14.495Z"
   },
   {
    "duration": 120,
    "start_time": "2021-11-16T09:24:46.630Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:28:27.882Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:29:54.281Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:30:45.936Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:31:06.300Z"
   },
   {
    "duration": 113,
    "start_time": "2021-11-16T09:31:37.208Z"
   },
   {
    "duration": 143,
    "start_time": "2021-11-16T09:31:48.656Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-16T09:31:55.678Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:32:08.535Z"
   },
   {
    "duration": 111,
    "start_time": "2021-11-16T09:32:10.120Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:32:15.732Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:32:29.423Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:03:03.074Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:10:01.288Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:10:46.923Z"
   },
   {
    "duration": 121,
    "start_time": "2021-11-16T10:37:46.494Z"
   },
   {
    "duration": 125,
    "start_time": "2021-11-16T10:38:20.632Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T10:46:53.001Z"
   },
   {
    "duration": 110,
    "start_time": "2021-11-16T10:48:25.775Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:50:18.720Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T10:50:37.649Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-16T10:50:51.884Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:51:56.237Z"
   },
   {
    "duration": 101,
    "start_time": "2021-11-16T10:53:13.791Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:55:59.186Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:10.751Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.038Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.174Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T10:56:49.414Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.680Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:50.370Z"
   },
   {
    "duration": 114,
    "start_time": "2021-11-16T10:59:34.518Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:01:41.201Z"
   },
   {
    "duration": 116,
    "start_time": "2021-11-16T11:01:48.754Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:16.685Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:19.479Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:47.067Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:49.353Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:03:07.835Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:03:07.953Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T11:07:52.072Z"
   },
   {
    "duration": 187,
    "start_time": "2021-11-16T11:09:23.468Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:10:01.455Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:05.069Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:10:13.376Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:14.434Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:22.853Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:27:29.279Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:29:08.919Z"
   },
   {
    "duration": 118,
    "start_time": "2021-11-16T11:29:46.703Z"
   },
   {
    "duration": 437,
    "start_time": "2021-11-16T11:36:02.181Z"
   },
   {
    "duration": 157,
    "start_time": "2021-11-16T11:36:14.388Z"
   },
   {
    "duration": 207,
    "start_time": "2021-11-16T11:47:15.898Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:53:52.092Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:53:52.236Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:59:12.005Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T12:00:33.446Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T12:02:14.453Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T12:02:39.512Z"
   },
   {
    "duration": 106,
    "start_time": "2021-11-16T12:03:03.460Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:37:21.139Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:37:22.229Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:38:38.806Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:38:41.958Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:43:46.551Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:58:21.835Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:59:21.872Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:59:45.352Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:59:49.646Z"
   },
   {
    "duration": 159,
    "start_time": "2021-11-17T21:02:26.949Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:03:53.461Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:03:53.694Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:05:28.145Z"
   },
   {
    "duration": 116,
    "start_time": "2021-11-17T21:05:57.787Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:06:37.993Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:06:38.261Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:11:54.358Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:12:43.846Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:13:08.773Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:14:44.441Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:42.059Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:15:51.995Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:53.923Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:55.282Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:16:28.492Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:16:32.603Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:17:06.941Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-17T21:18:05.733Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:21:35.255Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:21:37.804Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:23:06.071Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:23:24.799Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:23:32.591Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-17T21:28:31.559Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:28:45.448Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:17.303Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:29.617Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:32.681Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:11.474Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:14.791Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:53.943Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:56.165Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:37:16.590Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:37:22.702Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:38:03.479Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:08.601Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:12.928Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:48.896Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-17T21:38:49.171Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:39:57.889Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:39:58.057Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:41:20.108Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:41:20.629Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:42:49.136Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:43:15.137Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:43:16.766Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:43:31.711Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:43:36.312Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:08.825Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:10.119Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:13.748Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:45:22.219Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:45:33.412Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-17T21:46:01.885Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:46:03.628Z"
   },
   {
    "duration": 107,
    "start_time": "2021-11-17T21:47:32.512Z"
   },
   {
    "duration": 103,
    "start_time": "2021-11-17T21:50:36.243Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:28:31.440Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:29:00.168Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:31:27.008Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-18T06:35:34.288Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-18T06:38:04.527Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
